# =============================================================================
# Omniscient Architect - Environment Configuration
# =============================================================================
# Copy this file to .env and update values for your environment

# =============================================================================
# Database Configuration
# =============================================================================

# PostgreSQL connection password
POSTGRES_PASSWORD=localdev

# Full database URL (alternative to separate config)
# DATABASE_URL=postgresql://omniscient:localdev@localhost:5432/omniscient

# Database performance tuning (optional)
POSTGRES_SHARED_BUFFERS=256MB
POSTGRES_EFFECTIVE_CACHE_SIZE=1GB
POSTGRES_WORK_MEM=16MB

# =============================================================================
# Ollama / LLM Configuration
# =============================================================================

# Ollama service host
OLLAMA_HOST=http://localhost:11434

# Default embedding model
EMBEDDING_MODEL=nomic-embed-text

# Default LLM model for code analysis
DEFAULT_LLM_MODEL=qwen2.5-coder:1.5b

# =============================================================================
# Application Configuration
# =============================================================================

# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Application port (Streamlit)
APP_PORT=8501

# Maximum file upload size (MB)
MAX_FILE_SIZE_MB=10

# Maximum number of files to analyze
MAX_FILES=100

# =============================================================================
# RAG Configuration
# =============================================================================

# Chunking strategy: auto, fixed, semantic, ast
CHUNKING_STRATEGY=auto

# Target chunk size in tokens
CHUNK_SIZE=512

# Overlap ratio between chunks (0-1)
CHUNK_OVERLAP=0.1

# Vector dimensions (768 for nomic-embed-text)
EMBEDDING_DIMENSIONS=768

# Number of results for retrieval
TOP_K=5

# Hybrid search alpha (0=BM25 only, 1=vector only, 0.5=balanced)
HYBRID_ALPHA=0.5

# Auto-generate test questions on ingestion
AUTO_GENERATE_QUESTIONS=true

# Number of questions per document
QUESTIONS_PER_DOCUMENT=3

# =============================================================================
# Learning System Configuration
# =============================================================================

# Maximum learned facts to inject into context
MAX_LEARNED_FACTS=5

# Maximum reasoning chains to inject
MAX_REASONING_CHAINS=2

# Include few-shot reasoning examples
INCLUDE_FEW_SHOT_REASONING=true

# Minimum confidence threshold for using learned facts
MIN_FACT_CONFIDENCE=0.3

# =============================================================================
# Docker Configuration
# =============================================================================

# Docker Compose project name
COMPOSE_PROJECT_NAME=omniscient-architect

# Resource limits (used in docker-compose.yml)
POSTGRES_MEMORY_LIMIT=1G
POSTGRES_MEMORY_RESERVATION=512M
OLLAMA_MEMORY_LIMIT=4G
OLLAMA_MEMORY_RESERVATION=2G
APP_MEMORY_LIMIT=2G
APP_MEMORY_RESERVATION=512M

# =============================================================================
# Development Configuration
# =============================================================================

# Enable development mode features
DEV_MODE=false

# Enable hot reload (for development)
ENABLE_HOT_RELOAD=false

# Enable debug logging
DEBUG=false

# =============================================================================
# Security Configuration
# =============================================================================

# Enable CORS (set to false in production)
ENABLE_CORS=false

# Enable XSRF protection
ENABLE_XSRF_PROTECTION=true

# Secret key for session management (generate a random string)
# SECRET_KEY=your-secret-key-here

# =============================================================================
# Monitoring and Observability
# =============================================================================

# Enable metrics collection
ENABLE_METRICS=true

# Enable performance profiling
ENABLE_PROFILING=false

# Metrics export port
METRICS_PORT=9090
